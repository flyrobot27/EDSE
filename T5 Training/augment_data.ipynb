{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"neo4j\"))\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(name: str):\n",
    "    with driver.session() as session:\n",
    "        items = list()\n",
    "        result = driver.execute_query(f\"match (n:{name}) return n.name\")\n",
    "        for r in result.records:\n",
    "            if r.get(\"n.name\") is not None:\n",
    "                items.append(r.get(\"n.name\"))\n",
    "    \n",
    "    return items\n",
    "\n",
    "player_list = get_items(\"Player\")\n",
    "club_list = get_items(\"Club\")\n",
    "league_list = get_items(\"League\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of player list: 68599\n",
      "Length of club list: 264\n",
      "Length of League list: 35\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of player list:\", len(player_list))\n",
    "print(\"Length of club list:\",len(club_list))\n",
    "print(\"Length of League list:\", len(league_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "sentence_template_path = Path(\"./templates/sentence_template.json\")\n",
    "cypher_template_path = Path(\"./templates/cypher_template.json\")\n",
    "\n",
    "sentence_template = json.load(open(sentence_template_path))\n",
    "cypher_template = json.load(open(cypher_template_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernard Dumot\n",
      "Michel Albaladéjo\n",
      "Salih Altın\n",
      "Fußball-Regionalliga Südwest\n",
      "Serie D\n",
      "Brentford F.C.\n",
      "{1: {3177319328087872474: {'Salih Altın', 'Bernard Dumot'}, -8233536537466523547: {'Michel Albaladéjo'}, 2821498810510939170: {'Fußball-Regionalliga Südwest'}, -8754017992745699427: {'Serie D'}, -5574422191687174199: {'Brentford F.C.'}}}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "class Sampler:\n",
    "    def __init__(self, player_list = list(), clubs_list = list(), league_list = list()) -> None:\n",
    "        self.sampled_player_sentence = dict()\n",
    "        self.player_set: set = set(player_list).copy()\n",
    "        self.club_set: set = set(clubs_list).copy()\n",
    "        self.league_set: set = set(league_list).copy()\n",
    "    \n",
    "    def sample(self, tag: str, sentence_id: int, sentence_hash: str):\n",
    "        extract_pattern = r'<(\\w+)_(\\w+)>'\n",
    "        tag = re.match(extract_pattern, tag)\n",
    "        \n",
    "        tag_type = tag.group(1).lower()\n",
    "\n",
    "        if tag_type == \"player\":\n",
    "            return self.__sample_from_list(self.player_set, sentence_id, sentence_hash, tag_type)\n",
    "        elif tag_type == \"club\":\n",
    "            return self.__sample_from_list(self.club_set, sentence_id, sentence_hash, tag_type)\n",
    "        elif tag_type == \"league\":\n",
    "            return self.__sample_from_list(self.league_set, sentence_id, sentence_hash, tag_type)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tag type\")\n",
    "    \n",
    "    def __sample_from_list(self, sample_set: set, sentence_id: int, sentence_hash: str, tag_type: str):\n",
    "        already_sampled_item_dict: dict = self.sampled_player_sentence.get(sentence_id, dict())\n",
    "        dict_hash = hash(sentence_hash) ^ hash(tag_type)\n",
    "\n",
    "\n",
    "        already_sampled_item: dict = already_sampled_item_dict.get(dict_hash, set())\n",
    "\n",
    "        valid_samples = sample_set.difference(already_sampled_item)\n",
    "        sampled_item = random.choice(tuple(valid_samples)).strip()\n",
    "\n",
    "\n",
    "        already_sampled_item.add(sampled_item)\n",
    "        already_sampled_item_dict[dict_hash] = already_sampled_item\n",
    "        self.sampled_player_sentence[sentence_id] = already_sampled_item_dict\n",
    "\n",
    "        return sampled_item\n",
    "\n",
    "\n",
    "sampler = Sampler(player_list, club_list, league_list)\n",
    "sentence1 = \"The player <player_x> plays for <club_x> in the <league_x> league\"\n",
    "sentence2 = \"The player <player_y> in the <league_y> league\"\n",
    "print(sampler.sample(\"<player_x>\", 1, str(hash(sentence1))))\n",
    "print(sampler.sample(\"<player_y>\", 1, str(hash(sentence2))))\n",
    "print(sampler.sample(\"<player_z>\", 1, str(hash(sentence1))))\n",
    "print(sampler.sample(\"<league_x>\", 1, str(hash(sentence1))))\n",
    "print(sampler.sample(\"<league_y>\", 1, str(hash(sentence2))))\n",
    "print(sampler.sample(\"<club_x>\", 1, str(hash(sentence1))))\n",
    "print(sampler.sampled_player_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<league_x>', '<league_y>']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_tag(sentence: str):\n",
    "    pattern = r'(<\\w+_\\w+>)'\n",
    "    return re.findall(pattern, sentence)\n",
    "\n",
    "print(extract_tag(\"What is the list of players who have appeared in both <league_x> and <league_y>?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13715.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'What players have the unique experience of playing in both <league_x> Football League First Division and <league_y> Segunda Federación?', 'cypher': \"MATCH (p:Player)-[:PLAYED_FOR]->(:Club)-[:IS_IN]->(l:League) WHERE l.name IN ['<league_x> Football League First Division', '<league_y> Segunda Federación'] RETURN p.name\"}, {'query': 'Who has split their career between <league_x> Regionalliga and <league_y> EFL League Two?', 'cypher': \"MATCH (p:Player)-[:PLAYED_FOR]->(:Club)-[:IS_IN]->(l:League) WHERE l.name IN ['<league_x> Regionalliga', '<league_y> EFL League Two'] RETURN p.name\"}, {'query': \"Can you name the players who've competed in both <league_x> Oberliga Rheinland-Pfalz/Saar and <league_y> National League?\", 'cypher': \"MATCH (p:Player)-[:PLAYED_FOR]->(:Club)-[:IS_IN]->(l:League) WHERE l.name IN ['<league_x> Oberliga Rheinland-Pfalz/Saar', '<league_y> National League'] RETURN p.name\"}, {'query': 'Which individuals have football history in both <league_x> Ligue 2 and <league_y> Regionalliga West?', 'cypher': \"MATCH (p:Player)-[:PLAYED_FOR]->(:Club)-[:IS_IN]->(l:League) WHERE l.name IN ['<league_x> Ligue 2', '<league_y> Regionalliga West'] RETURN p.name\"}, {'query': 'What is the list of players who have appeared in both <league_x> Serie C and <league_y> EFL League One?', 'cypher': \"MATCH (p:Player)-[:PLAYED_FOR]->(:Club)-[:IS_IN]->(l:League) WHERE l.name IN ['<league_x> Serie C', '<league_y> EFL League One'] RETURN p.name\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_sentence(sentence_list: list, sentence_id: int, iter_count: int = 5000):\n",
    "    sampler = Sampler(player_list, club_list, league_list)\n",
    "    sentence_cypher = list()\n",
    "    cypher_query = cypher_template.get(str(sentence_id))\n",
    "    for _ in tqdm(range(iter_count)):\n",
    "        sentence: str = random.choice(sentence_list)\n",
    "        tags = extract_tag(sentence)\n",
    "\n",
    "        # make a copy of the cypher query\n",
    "        sentence_query = cypher_query\n",
    "        for tag in tags:\n",
    "            sample_name = sampler.sample(tag, sentence_id, str(hash(sentence)))\n",
    "            sentence = sentence.replace(tag, tag + \" \" + sample_name)\n",
    "            sentence_query = sentence_query.replace(tag, tag + \" \" + sample_name)\n",
    "\n",
    "        sentence_cypher.append({\n",
    "            \"query\": sentence,\n",
    "            \"cypher\": sentence_query\n",
    "        })    \n",
    "    return sentence_cypher\n",
    "\n",
    "print(generate_sentence(sentence_template[\"11\"], 11, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 690.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 744.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 992.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1074.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1126.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29269.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11187.79it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21788.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 68.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 70.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 70.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "# Define a function to generate sentences for a given sentence template\n",
    "def generate_sentences(template_id):\n",
    "    return generate_sentence(sentence_template[str(template_id)], int(template_id), iter_count=10)\n",
    "\n",
    "def validate_query(query: str):\n",
    "    with driver.session() as _:\n",
    "        query = \"PROFILE \" + query\n",
    "        try:\n",
    "            driver.execute_query(query)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "# Create a multiprocessing pool\n",
    "with multiprocessing.Pool(processes=6) as pool:\n",
    "    # Iterate over all sentence templates and call generate_sentence function using multiprocessing\n",
    "    results = pool.map(generate_sentences, sentence_template.keys())\n",
    "\n",
    "\n",
    "combined_result = list(itertools.chain.from_iterable(results))\n",
    "json.dump(combined_result, open(\"generated_sentences.json\", \"w\", encoding=\"utf8\"), indent=4, ensure_ascii=False)\n",
    "\n",
    "# validate result\n",
    "for result in combined_result:\n",
    "    cypher = result.get(\"cypher\")\n",
    "    if not validate_query(cypher):\n",
    "        combined_result.remove(result)\n",
    "        print(cypher)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
